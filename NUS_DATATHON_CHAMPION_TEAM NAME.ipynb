{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas \n",
    "#%pip install matplotlib\n",
    "#%pip install sklearn\n",
    "#%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .csv file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data from csv file\n",
    "filepath = \"./data/catA_train.csv\" \n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data missing: Employee Data\n",
    "We aim to fill in the missing employee data using linear regression.\n",
    "We construct a helper function that returns cleansed data for the input dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing data treatment - Regression to fill in missing values for employees\n",
    "def regress_fill_employee_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    #create a new cleansed data\n",
    "    cleansed_data = data\n",
    "\n",
    "    #linear regression to fill all empty cells in employees\n",
    "    for employee_type in [\"Employees (Domestic Ultimate Total)\",\"Employees (Global Ultimate Total)\",\"Employees (Single Site)\"]:\n",
    "        X_features = [\"Sales (Domestic Ultimate Total USD)\",\"Is Domestic Ultimate\",\"Is Global Ultimate\"]\n",
    "        y_value = [employee_type]\n",
    "        \n",
    "        columns_to_check = [employee_type]\n",
    "        train_data = data.dropna(subset=columns_to_check)\n",
    "        predict_data = data[data[employee_type].isnull()]\n",
    "        \n",
    "        X = train_data[X_features]\n",
    "        y = train_data[y_value]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        linear_regression_model = LinearRegression()\n",
    "        linear_regression_model.fit(X_train,y_train)\n",
    "        \n",
    "        y_pred = linear_regression_model.predict(X_test)\n",
    "    \n",
    "        X_need = predict_data[X_features]\n",
    "        y_need = predict_data[y_value]\n",
    "        y_result = linear_regression_model.predict(X_need)\n",
    "        y_need[employee_type] = y_result\n",
    "        cleansed_data.loc[predict_data.index, y_value] = y_need\n",
    "\n",
    "    return cleansed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "We aim to investigate the effect of entity type on the sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Get the dimensions of the DataFrame\n",
    "print(data.shape)\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(1101)\n",
    "\n",
    "# Convert categorical variables to numeric codes\n",
    "data['Entity.Type'] = np.where(data['Entity.Type'] == \"Subsidiary\", 1,\n",
    "                               np.where(data['Entity.Type'] == \"Parent\", 2, 3))\n",
    "print(data['Entity.Type'].value_counts())\n",
    "\n",
    "data['Ownership.Type'] = np.where(data['Ownership.Type'] == \"Private\", 1,\n",
    "                                  np.where(data['Ownership.Type'] == \"Public\", 2,\n",
    "                                           np.where(data['Ownership.Type'] == \"Public Sector\", 3, 4)))\n",
    "print(data['Ownership.Type'].value_counts())\n",
    "\n",
    "# Select specific columns to keep for domestic and global data\n",
    "keep_dom = [\"SIC.Code\", \"Entity.Type\", \"Ownership.Type\", \"Employees..Domestic.Ultimate.Total.\", \"Sales..Domestic.Ultimate.Total.USD.\"]\n",
    "keep_global = [\"SIC.Code\", \"Entity.Type\", \"Ownership.Type\", \"Employees..Global.Ultimate.Total.\", \"Sales..Global.Ultimate.Total.USD.\"]\n",
    "\n",
    "# Subset the data for domestic and global\n",
    "data_dom = data[keep_dom]\n",
    "print(data_dom.head())\n",
    "\n",
    "# Find the maximum value of domestic sales\n",
    "print(data_dom['Sales..Domestic.Ultimate.Total.USD.'].max())\n",
    "\n",
    "# Recode domestic sales into a binary variable\n",
    "data['Sales..Domestic.Ultimate.Total.USD.'] = np.where(data['Sales..Domestic.Ultimate.Total.USD.'] < 0.8 * 10**10, 1, 2)\n",
    "print(data['Sales..Domestic.Ultimate.Total.USD.'].value_counts())\n",
    "\n",
    "# Subset the data for global\n",
    "data_global = data[keep_global]\n",
    "print(data_global.head())\n",
    "\n",
    "# Find the maximum value of global sales\n",
    "print(data_global['Sales..Global.Ultimate.Total.USD.'].max())\n",
    "\n",
    "# Recode global sales into a binary variable\n",
    "data['Sales..Global.Ultimate.Total.USD.'] = np.where(data['Sales..Global.Ultimate.Total.USD.'] < 5.2 * 10**10, 1, 2)\n",
    "print(data['Sales..Global.Ultimate.Total.USD.'].value_counts())\n",
    "\n",
    "K = 10\n",
    "wss = np.zeros(K)\n",
    "for k in range(1, K+1):\n",
    "    kmeans_model = KMeans(n_clusters=k).fit(data_dom[['SIC_Code', 'Entity_Type', 'Ownership_Type', 'Sales_Domestic_Ultimate_Total_USD']])\n",
    "    wss[k-1] = sum(kmeans_model.inertia_)\n",
    "\n",
    "plt.plot(range(1, K+1), wss, color='red', marker='o', linestyle='-', linewidth=2, markersize=5)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Within Sum of Squares')\n",
    "plt.show()\n",
    "\n",
    "kout_domestic = KMeans(n_clusters=3).fit(data[['Sales_Domestic_Ultimate_Total_USD', 'Entity_Type']])\n",
    "print(kout_domestic.labels_)\n",
    "print(kout_domestic.cluster_centers_)\n",
    "print(np.bincount(kout_domestic.labels_))\n",
    "\n",
    "k = 30\n",
    "print(data_dom.shape)\n",
    "number = data_dom.shape[0]\n",
    "test_indices = np.random.choice(range(number), 21000, replace=False)\n",
    "train_dom_X = data_dom.drop(test_indices)\n",
    "test_dom_X = data_dom.iloc[test_indices]\n",
    "print(train_dom_X.shape)\n",
    "\n",
    "train_dom_Y = data_dom['Sales_Domestic_Ultimate_Total_USD'].drop(test_indices)\n",
    "test_dom_Y = data_dom['Sales_Domestic_Ultimate_Total_USD'].iloc[test_indices]\n",
    "\n",
    "knn_pred = KNeighborsClassifier(n_neighbors=1).fit(train_dom_X, train_dom_Y).predict(test_dom_X)\n",
    "\n",
    "acck = np.zeros(k)\n",
    "for j in range(1, k+1):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=j).fit(train_dom_X, train_dom_Y)\n",
    "    knn_pred = knn_model.predict(test_dom_X)\n",
    "    tablek = pd.crosstab(knn_pred, test_dom_Y)\n",
    "    acck[j-1] = np.trace(tablek) / np.sum(tablek.values)\n",
    "\n",
    "bestk = np.argmax(acck) + 1\n",
    "print(bestk)\n",
    "\n",
    "knn_pred = KNeighborsClassifier(n_neighbors=2).fit(train_dom_X, train_dom_Y).predict_proba(test_dom_X)\n",
    "print(knn_pred)\n",
    "\n",
    "tableknn = pd.crosstab(knn_pred, test_dom_Y)\n",
    "print(tableknn)\n",
    "\n",
    "accknn = np.trace(tableknn) / np.sum(tableknn.values)\n",
    "print(accknn)\n",
    "\n",
    "fnr_knn = tableknn.iloc[0, 1] / (tableknn.iloc[0, 1] + tableknn.iloc[1, 1])\n",
    "print(fnr_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Result\n",
    "From the exploratory data analysis we performed, we decided to categorize the companies based on their entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data conversion from strings to integers for \"Entity\"\n",
    "We convert entity to integers for ease of dealing with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert entity to numbers\n",
    "def convert_to_number(cleansed_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    convert = []\n",
    "    for i in range(len(cleansed_data)):\n",
    "        entity = data.iloc[i]['Entity Type']\n",
    "        if entity == 'Subsidiary':\n",
    "            l = 1\n",
    "        elif entity == 'Parent':\n",
    "            l = 2\n",
    "        elif entity == 'Branch':\n",
    "            l = 3\n",
    "        elif entity == 'Independent':\n",
    "            l = 4\n",
    "        convert.append(l)\n",
    "    cleansed_data['entity type conversion'] = convert\n",
    "    return cleansed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor: Predict Sales based on Number of Employees in each Entity Category\n",
    "## Testing the model with Global Sales vs Parent entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) - TESTING WITH PARENTS + GLOBAL SALES\n",
    "entity_type = ['Subsidiary','Parent', 'Branch', 'Independent' ]\n",
    "Parent = cleansed_data[cleansed_data['Entity Type'] == 'Parent']\n",
    "\n",
    "# Generate some example data\n",
    "X = np.array(np.log(Parent['Employees (Single Site)'])).reshape(-1,1)\n",
    "y = np.log(Parent['Sales (Global Ultimate Total USD)'])\n",
    "\n",
    "# Create a decision tree regressor\n",
    "regressor = DecisionTreeRegressor(max_depth=50)  # You can adjust the max_depth parameter\n",
    "\n",
    "# Fit the model to the data\n",
    "regressor.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "X_test = np.arange(0.0, 10.0, 0.01)[:, np.newaxis]\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(X, y, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_pred, color=\"cornflowerblue\", label=\"prediction\")\n",
    "plt.xlabel(\"Employees (Single site)\")\n",
    "plt.ylabel(\"Sales (Global Domestic Ultimate)\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for demonstration\n",
    "X = np.array(np.log(Parent['Employees (Single Site)'])).reshape(-1,1)\n",
    "y = np.log(Parent['Sales (Global Ultimate Total USD)'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(max_depth = 50)\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "- In our testing between Sales (Global) and Employee (Single Site), the Decision Tree Regression yields reliable prediction with small Mean Squared Error & Mean Absolute Error\r",
    "- \n",
    "Now, we will loop through to find what kind of sales (Global or Domestic) as the y-variable and what kind of employees (Single Unit, Domestic, Global) would be perfomed with greater accuracy in Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all the groups first\r\n",
    "for entity in entity_type:\r\n",
    "    group = cleansed_data[cleansed_data['Entity Type'] == entity]\r\n",
    "    \r\n",
    "    #Loop through all the employees type for this group\r\n",
    "    for employee_type in ['Employees (Single Site)','Employees (Domestic Ultimate Total)','Employees (Domestic Ultimate Total)']:\r\n",
    "        for sale_type in ['Sales (Domestic Ultimate Total USD)','Sales (Global Ultimate Total USD)']:\r\n",
    "            # Generate some example data\r\n",
    "            X = np.array(np.log(group[employee_type])).reshape(-1,1)\r\n",
    "            y = np.log(group[sale_type])\r\n",
    "\r\n",
    "            # Create a decision tree regressor\r\n",
    "            regressor = DecisionTreeRegressor(max_depth=50)  # You can adjust the max_depth parameter\r\n",
    "            \r\n",
    "            # Fit the model to the data\r\n",
    "            regressor.fit(X, y)\r\n",
    "            \r\n",
    "            # Make predictions\r\n",
    "            X_test = np.arange(0.0, 10.0, 0.01)[:, np.newaxis]\r\n",
    "            y_pred = regressor.predict(X_test)\r\n",
    "            \r\n",
    "            # Plot the results\r\n",
    "            plt.figure()\r\n",
    "            plt.scatter(X, y, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\r\n",
    "            plt.plot(X_test, y_pred, color=\"cornflowerblue\", label=\"prediction\")\r\n",
    "            plt.xlabel(employee_type)\r\n",
    "            plt.ylabel(sale_type)\r\n",
    "            plt.title(f\"Decision Tree Regression for {entity}: {employee_type} and {sale_type}\")\r\n",
    "            plt.legend()\r\n",
    "            plt.show()\r\n",
    "\r\n",
    "            # Sample data for demonstration\r\n",
    "            X = np.array(np.log(group[employee_type])).reshape(-1,1)\r\n",
    "            y = np.log(group[sale_type])\r\n",
    "            \r\n",
    "            # Split the data into training and testing sets\r\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
    "            \r\n",
    "            # Create a DecisionTreeRegressor\r\n",
    "            regressor = DecisionTreeRegressor(max_depth = 50)\r\n",
    "            \r\n",
    "            # Fit the regressor to the training data\r\n",
    "            regressor.fit(X_train, y_train)\r\n",
    "            \r\n",
    "            # Make predictions on the test set\r\n",
    "            y_pred = regressor.predict(X_test)\r\n",
    "            \r\n",
    "            # Calculate the Mean Squared Error (MSE)\r\n",
    "            mse = mean_squared_error(y_test, y_pred)\r\n",
    "            mae = mean_absolute_error(y_test, y_pred)\r\n",
    "            print(f\"Errors for {entity}: {employee_type} and {sale_type}\")\r\n",
    "            print(\"Mean Squared Error:\", mse)\r\n",
    "            print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through all the entity type to find the bext max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errors = {'Subsidiary':[],'Parent':[], 'Branch':[], 'Independent':[]}\n",
    "\n",
    "for entity in entity_type:\n",
    "    for max_depth in range(1,11):\n",
    "        group = data[data['Entity Type'] == entity]\n",
    "        \n",
    "        # Generate some example data\n",
    "        X = np.array(np.log(group['Employees (Domestic Ultimate Total)'])).reshape(-1,1)\n",
    "        y = np.log(group['Sales (Domestic Ultimate Total USD)'])\n",
    "        \n",
    "        # Create a decision tree regressor\n",
    "        regressor = DecisionTreeRegressor(max_depth=50)  # You can adjust the max_depth parameter\n",
    "        \n",
    "        # Fit the model to the data\n",
    "        regressor.fit(X, y)\n",
    "        \n",
    "        # Make predictions\n",
    "        X_test = np.arange(0.0, 10.0, 0.01)[:, np.newaxis]\n",
    "        y_pred = regressor.predict(X_test)\n",
    "\n",
    "        # Sample data for demonstration\n",
    "        X = np.array(np.log(group['Employees (Domestic Ultimate Total)'])).reshape(-1,1)\n",
    "        y = np.log(group['Sales (Domestic Ultimate Total USD)'])\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Create a DecisionTreeRegressor\n",
    "        regressor = DecisionTreeRegressor(max_depth = max_depth)\n",
    "        \n",
    "        # Fit the regressor to the training data\n",
    "        regressor.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = regressor.predict(X_test)\n",
    "        \n",
    "        # Calculate the Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mean_errors[entity].append((mse+mae)/2)\n",
    "\n",
    "param = {}\n",
    "for key,list in mean_errors.items():\n",
    "    min_index = list.index(min(list))\n",
    "    param[key] = (min_index + 1)*10\n",
    "    print(f\"Best max depth for {key}: {(min_index + 1)*10}\")\n",
    "\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remarks\n",
    "- We will thus choose max_depth based on our algorithm to find the optimal parameter that yeilds smallest error.\n",
    "- After choosing the appropriate paramemters, we start constructing our final functions below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "\n",
    "    #remove negative sales data\n",
    "    hidden_data = hidden_data[hidden_data['Sales (Domestic Ultimate Total USD)'] > 0]\n",
    "    hidden_data = hidden_data[hidden_data['Sales (Global Ultimate Total USD)'] > 0]\n",
    "\n",
    "    #fill missing employees data\n",
    "    cleansed_data = regress_fill_employee_data(hidden_data)\n",
    "\n",
    "    result = [] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_csv(filepath)\n",
    "test_df = test_df.drop(columns=['Sales (Domestic Ultimate Total USD)'])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
